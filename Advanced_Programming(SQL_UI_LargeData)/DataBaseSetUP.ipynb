{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #-----------------------setup database -----------------------------------------\n",
    "database_username =\"root\"\n",
    "database_password =\"lalaland\"\n",
    "database_ip =\"localhost\"\n",
    "database_name =\"pro_database\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YorkSqlTool():\n",
    "    #===========  SQL TOOLS to make life easier ====================================\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # Drop database table if exists\n",
    "    def sqlDropTable(self,cursor, name):\n",
    "        sql = \"DROP TABLE IF EXISTS %s\" %name\n",
    "        cursor.execute(sql)\n",
    "    \n",
    "    #Show all the table\n",
    "    def sqlShowTable(self,cursor):\n",
    "        k = cursor.execute(\"SHOW TABLES\")\n",
    "        for x in k:\n",
    "            print(x)\n",
    "        \n",
    "    #Create a table    \n",
    "    def sqlCreateTable(self,cursor, tableName, dataType):\n",
    "        cursor.execute(\"CREATE TABLE %s %s\" %(tableName, dataType))\n",
    "    \n",
    "    #Drop all data in db\n",
    "    def sqlDropAllTable(self,cursor):\n",
    "        k = cursor.execute(\"SHOW TABLES\")\n",
    "        for x in k:\n",
    "            self.sqlDropTable(self,cursor,x[0])\n",
    "    \n",
    "    #Set foreignkey in table\n",
    "    def sqlSetForeignKey(self,cursor, Table, key, refTable, refKey):\n",
    "        sql = \"ALTER TABLE %s ADD FOREIGN KEY (%s)\\\n",
    "                REFERENCES %s(%s);\"%(Table, key, refTable, refKey)\n",
    "        cursor.execute(sql)\n",
    "    \n",
    "    #drop database if it already that and create new one\n",
    "    def sqlResetDatabase(self,cursor,dbName):\n",
    "        cursor.execute(\"DROP DATABASE IF EXISTS %s\"%dbName)\n",
    "        cursor.execute(\"CREATE DATABASE %s\"%dbName)\n",
    "        cursor.execute(\"USE %s\"%dbName)\n",
    "        \n",
    "    # Line by line insert    \n",
    "    def sqlInsertData(self,dbEngine, table, keys, primaryKey, dataFrame, update = False):\n",
    "        val = \"%s,\"*len(keys) # how many needed to be uploaded\n",
    "        val = val[0:-1]     # remove the , at the end in list\n",
    "        \n",
    "        col = \"\"\n",
    "        \n",
    "        for i in keys:\n",
    "            col = col +\"`%s`, \" %i \n",
    "        col = col[0:-2] \n",
    "        if update:\n",
    "            pass\n",
    "        else:\n",
    "            sql = \"INSERT INTO %s (%s) VALUES (%s)\\\n",
    "                ON DUPLICATE KEY UPDATE \\\n",
    "                `%s`= VALUES(`%s`);\"%(table,col, val, primaryKey, primaryKey)\n",
    "        for index,row in dataFrame.iterrows():\n",
    "            value = row\n",
    "            dbEngine.execute(sql,value)\n",
    "    #==================== This is kind of a cheat ===========================\n",
    "    #pandas to sql is much faster than line by line upload but it does not suport \n",
    "    #upsert so this block of code is a work around by creating a temp table that\n",
    "    #muches the final table and simply merge them and if entries already exit, it will \n",
    "    #simply pass, we can create an change the update statment if update is required later\n",
    "    \n",
    "    #Mergin temp table to target table\n",
    "    def sqlInsertTempTable(self,cursor, Table, TempTable, primaryKey):\n",
    "        \n",
    "        sql = \"INSERT INTO %s SELECT * FROM %s\\\n",
    "             ON DUPLICATE KEY UPDATE\\\n",
    "             `%s`= VALUES(`%s`);\"\\\n",
    "             %(Table, TempTable, primaryKey, primaryKey)\n",
    "        cursor.execute(sql)\n",
    "    \n",
    "        \n",
    "    #upload data to a temp table in the database\n",
    "    def sqlUploadPandas(self, cursor, df, keys):\n",
    "        self.sqlDropTable(cursor, \"temp\")\n",
    "        tempDataInventroy = df.loc[:,keys] \n",
    "        tempDataInventroy =tempDataInventroy.drop_duplicates().astype(str)\n",
    "        tempDataInventroy.to_sql(name='temp',con=cursor, if_exists=\"append\",\\\n",
    "                          index = False ,chunksize=50)\n",
    "    #Function to enable and disable foreign key check to speed up upload if needed    \n",
    "    def sqlDisableFkey(self,dbEngine):\n",
    "            sql =\"SET foreign_key_checks = 0\"\n",
    "            dbEngine.execute(sql) \n",
    "    def sqlEnbleFkey(self,dbEngine):\n",
    "            sql =\"SET foreign_key_checks = 1\"\n",
    "            dbEngine.execute(sql)     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YorkDb(YorkSqlTool):\n",
    "    dbUsername = None\n",
    "    dbPassword = None\n",
    "    dbIp       = None\n",
    "    dbName     = None\n",
    "    dbEngine   = None\n",
    "     \n",
    "    #============= setup the required items for db ====================================\n",
    "    def __init__(self,dbUsername, dbPassword, dbIp, dbName):\n",
    "        self.dbUsername = dbUsername,\n",
    "        self.dbPassword = dbPassword\n",
    "        self.dbIp = dbIp\n",
    "        self.dbName = dbName\n",
    "        super().__init__()\n",
    "      \n",
    "    #============ start connection to db =============================================   \n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.dbEngine = create_engine('mysql+mysqlconnector://{0}:{1}@{2}'.\n",
    "                    format(database_username, database_password, \n",
    "                    database_ip))\n",
    "            #check if db exist if not make one \n",
    "            self.dbEngine.execute(\"CREATE DATABASE IF NOT EXISTS %s\"%database_name)\n",
    "            self.dbEngine.execute(\"USE  %s\" %database_name)\n",
    "            #check if tables are correct if not make new ones\n",
    "            tableCount = self.dbEngine.execute(\"SELECT COUNT(DISTINCT `table_name`)\\\n",
    "                                            FROM `information_schema`.`columns` \\\n",
    "                                            WHERE `table_schema` = '%s'\"%database_name)\n",
    "\n",
    "            k = tableCount.fetchall()[0][0]\n",
    "            if k < 2:\n",
    "                self.sqlResetDatabase(self.dbEngine,database_name)\n",
    "                self.createCustomerTables()                  \n",
    "\n",
    "        except:\n",
    "            print(\"Connection Failed\")\n",
    "            return False\n",
    "        \n",
    "\n",
    "\n",
    "        return True   \n",
    "    \n",
    "    #=========== create schema for  this db ==========================================\n",
    "    \"\"\"This create all the tables to store the data for sql server\n",
    "    The function takes one sql engine object and create the reqired table within\n",
    "    the database\"\"\"\n",
    "   \n",
    "    def createCustomerTables(self):\n",
    "        if self.dbEngine ==None:\n",
    "            self.connect()\n",
    "        #As we creating a complete new tables, we are going to drop the old DB   \n",
    "        self.sqlResetDatabase(self.dbEngine,database_name)\n",
    "        self.sqlShowTable(self.dbEngine)\n",
    "\n",
    "        #=========== start creating tables ===================\n",
    "        #************ dataInventory file *********************\n",
    "        #------------- owner table ===========================\n",
    "        \n",
    "        ownerTableType = \"\"\"\n",
    "            (\n",
    "              `OWNER ID`      VARCHAR(16) PRIMARY KEY,\\\n",
    "              `OWNER NAME`    VARCHAR(128),\\\n",
    "              `OWNER ADDRESS` VARCHAR(128),\\\n",
    "              `OWNER CITY`    VARCHAR(128),\\\n",
    "              `OWNER STATE`   VARCHAR(128),\\\n",
    "              `OWNER ZIP`     VARCHAR(16)\n",
    "            );\n",
    "          \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"owner\", ownerTableType)\n",
    "    #================ program ===========================    \n",
    "        programTableType = \"\"\"\n",
    "            (`RECORD ID` VARCHAR(16) PRIMARY KEY,\n",
    "            ` PROGRAM NAME` VARCHAR(128),\\\n",
    "            `PROGRAM ELEMENT (PE)` VARCHAR(16),\n",
    "            `FACILITY ID` VARCHAR(16)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"program\", programTableType)\n",
    "        \n",
    "    #================ program element ===========================\n",
    "        progElemTableType = \"\"\"\n",
    "            (`PROGRAM ELEMENT (PE)` VARCHAR(16) PRIMARY KEY,\n",
    "            `PE DESCRIPTION` VARCHAR(128),\\\n",
    "            `SEAT` VARCHAR(64)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"program_elem\", progElemTableType)\n",
    "    #================= facility ================================\n",
    "        facilityTableType = \"\"\"\n",
    "            (`FACILITY ID`       VARCHAR(16) PRIMARY KEY,\n",
    "            `FACILITY NAME`      VARCHAR(128),\n",
    "            `FACILITY ADDRESS`   VARCHAR(128),\n",
    "            `FACILITY CITY`      VARCHAR(128),\n",
    "            `FACILITY  STATE`    VARCHAR(128),\n",
    "            `FACILITY ZIP`       VARCHAR(40),\n",
    "            `Location`           VARCHAR(64),\n",
    "            `Census Tracts 2010` VARCHAR(128),\n",
    "            `2011 Supervisorial District Boundaries (Official)`\\\n",
    "                VARCHAR(128),\n",
    "            `Board Approved Statistical Areas` VARCHAR(128),\n",
    "            `OWNER ID` VARCHAR(16)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"facility\", facilityTableType)\n",
    "    \n",
    "    #================ End of dataInventory file ===============\n",
    "    \n",
    "    #************ Inspections file *********************\n",
    "    #================= inspections ================================\n",
    "        inspectTableType = \"\"\"\n",
    "            (`SERIAL NUMBER`  VARCHAR(16) PRIMARY KEY,\n",
    "            `ACTIVITY DATE`  DATE,\\\n",
    "            `OWNER ID`       VARCHAR(16),\n",
    "            `FACILITY ID`    VARCHAR(16),\n",
    "            `RECORD ID`      VARCHAR(16),\n",
    "            `PROGRAM STATUS` VARCHAR(16),\n",
    "            `SERVICE CODE`   VARCHAR(16),\n",
    "            `SCORE`          FLOAT(8),\n",
    "            `GRADE`          VARCHAR(8),\n",
    "            `EMPLOYEE ID`    VARCHAR(16)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"inspections\", inspectTableType)\n",
    "    \n",
    "    #=============== Service ============================\n",
    "        serviceTableType = \"\"\"\n",
    "            (`SERVICE CODE`  VARCHAR(16) PRIMARY KEY,\n",
    "            `SERVICE DESCRIPTION`  VARCHAR(128)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"service\", serviceTableType)\n",
    "    \n",
    "    #================ End of Inspections file ===============\n",
    "    \n",
    "    #************ violation file *********************\n",
    "    #================= violation ================================\n",
    "        violationTableType = \"\"\"\n",
    "            (`SERIAL NUMBER`           VARCHAR(16),\n",
    "            `VIOLATION  STATUS`        VARCHAR(128),\n",
    "            `VIOLATION CODE`           VARCHAR(16),\n",
    "            `VIOLATION DESCRIPTION`    VARCHAR(128),\n",
    "            `POINTS`                   FLOAT(16)\n",
    "            )\n",
    "            \"\"\"\n",
    "        self.sqlCreateTable(self.dbEngine  , \"violation\", violationTableType)\n",
    "        \n",
    "    \n",
    "    #================= add foreign keys =========================\n",
    "    #================= Programs ================================\n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"facility\", \"`OWNER ID`\",\\\n",
    "                         \"owner\", \"`OWNER ID`\")\n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"program\", \"`PROGRAM ELEMENT (PE)`\",\\\n",
    "                         \"program_Elem\", \"`PROGRAM ELEMENT (PE)`\")  \n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"program\", \"`FACILITY ID`\",\\\n",
    "                         \"facility\", \"`FACILITY ID`\") \n",
    "    \n",
    "    #================= Inspections ==============================\n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"inspections\", \"`SERVICE CODE`\",\\\n",
    "                     \"service\", \"`SERVICE CODE`\")    \n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"inspections\", \"`RECORD ID`\",\\\n",
    "                     \"program\", \"`RECORD ID`\")\n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"inspections\", \"`OWNER ID`\",\\\n",
    "                     \"owner\", \"`OWNER ID`\") \n",
    "        \n",
    "        self.sqlSetForeignKey(self.dbEngine  , \"inspections\", \"`FACILITY ID`\",\\\n",
    "                 \"facility\", \"`FACILITY ID`\") \n",
    "    \n",
    "    #function return dataFrame with the desired list of data where duplicates are removed\n",
    "    #================= this end the schema  ===========================================\n",
    "    \n",
    "    \"\"\"\n",
    "    Because the schema fixes the table structure this part load the three\n",
    "     different data sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    #function return dataFrame with the desired list of data where duplicates are removed\n",
    "    def removeDup(self,dataFrame,args):\n",
    "        newDataFrame = dataFrame[args]\n",
    "        return newDataFrame.drop_duplicates().astype(str)\n",
    "    #==================== Upload Inventroy files ============================\n",
    "    \n",
    "    def uploadSqlInventroy(self, dataInventroy):\n",
    "        start = time.time()\n",
    "        #connect to dp if there is no connection\n",
    "        if self.dbEngine ==None:\n",
    "            self.connect()\n",
    "        #spliting Inventroy data into their respective dataframe and remove any dupication\n",
    "        #========================================================================\n",
    "        keyOwner = [\"OWNER ID\", \"OWNER NAME\",\\\n",
    "                    \"OWNER ADDRESS\", \"OWNER CITY\",\\\n",
    "                    \"OWNER STATE\", \"OWNER ZIP\"]\n",
    "    \n",
    "        dataOwner = self.removeDup(dataInventroy, keyOwner)\n",
    "        \n",
    "        #load data to database\n",
    "        \n",
    "        self.sqlUploadPandas(self.dbEngine, dataInventroy, keyOwner)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'owner', 'temp', \"OWNER ID\")\n",
    "        \n",
    "        #Program element\n",
    "        keyProgElem = [\"PROGRAM ELEMENT (PE)\",\\\n",
    "                       \"PE DESCRIPTION\",\\\n",
    "                       \"SEAT\"]\n",
    "        \n",
    "        #Program element is an special case where there are only 24 of PE and PE DESCRIPTION and seat\n",
    "        # are always the same.\n",
    "        \n",
    "        #dataProgElem = dataInspections[keyProgElem].drop_duplicates(subset=\"PROGRAM ELEMENT (PE)\")\n",
    "        self.sqlUploadPandas(self.dbEngine, dataInventroy,  keyProgElem)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'program_elem', 'temp', \"PROGRAM ELEMENT (PE)\")\n",
    "        \n",
    "        #Facility ----------------------------------------------------------\n",
    "    \n",
    "        keyFacility = [\"FACILITY ID\",'FACILITY NAME',\\\n",
    "                                   'FACILITY ADDRESS','FACILITY CITY',\\\n",
    "                                   'FACILITY  STATE', 'FACILITY ZIP',\n",
    "                                    'Location', 'Census Tracts 2010',\\\n",
    "                                    '2011 Supervisorial District Boundaries (Official)',\n",
    "                                    'Board Approved Statistical Areas',\\\n",
    "                                     'OWNER ID']\n",
    "    \n",
    "        self.sqlUploadPandas(self.dbEngine, dataInventroy,  keyFacility)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'facility', 'temp', \"FACILITY ID\")\n",
    "        \n",
    "        #===================  Program ======================================== \n",
    "    \n",
    "        keyProgram = ['RECORD ID', ' PROGRAM NAME',\\\n",
    "                                     'PROGRAM ELEMENT (PE)',\"FACILITY ID\"]\n",
    "        self.sqlUploadPandas(self.dbEngine, dataInventroy, keyProgram)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'program', 'temp', \"RECORD ID\")\n",
    "    \n",
    "        print (\"Inventroy loaded in %.2f\" %(time.time()-start))\n",
    "        \n",
    "        \n",
    "#==================== End of inventroy ============================================================\n",
    "\n",
    "    def uploadSqlInspections(self,dataInspections):\n",
    "        start = time.time()\n",
    "        #connect to dp if there is no connection\n",
    "        if self.dbEngine ==None:\n",
    "            self.connect()\n",
    "        \n",
    "        #==========================================================================\n",
    "        #spliting Inspections data into their respective dataframe\n",
    "        #dropping all data that are dupication bettween inspections.csv and program.csv\n",
    "        #========================================================================\n",
    "        \n",
    "        keyProgramService = ['SERVICE CODE', 'SERVICE DESCRIPTION']\n",
    "    \n",
    "        self.sqlUploadPandas(self.dbEngine, dataInspections, keyProgramService)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'service', 'temp', \"SERVICE CODE\")\n",
    "         \n",
    "        #=== There are more data in inspection than inventory so the owner table need to be updated\n",
    "        #=== with the latest data\n",
    "    \n",
    "    \n",
    "        keyInspectOwner = ['OWNER ID', 'OWNER NAME']\n",
    "        inspectOwner = self.removeDup(dataInspections, keyInspectOwner)\n",
    "        \n",
    "        keyOwner = [\"OWNER ID\", \"OWNER NAME\",\\\n",
    "                    \"OWNER ADDRESS\", \"OWNER CITY\",\\\n",
    "                    \"OWNER STATE\", \"OWNER ZIP\"]\n",
    "    \n",
    "        inspectOwner = inspectOwner.reindex(columns = keyOwner )\n",
    "        \n",
    "        #=== fill missing data with None, as the schema reqired\n",
    "        inspectOwner = inspectOwner.where(pd.notnull(inspectOwner), None)\n",
    "        self.sqlUploadPandas(self.dbEngine, inspectOwner, keyOwner)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'owner', 'temp', \"OWNER ID\")\n",
    "        \n",
    "        #============ have to do the same for facility but faci\n",
    "    \n",
    "        keyFacility = [\"FACILITY ID\",'FACILITY NAME',\\\n",
    "                                   'FACILITY ADDRESS','FACILITY CITY',\\\n",
    "                                   'FACILITY  STATE', 'FACILITY ZIP',\n",
    "                                    'Location', 'Census Tracts 2010',\\\n",
    "                                    '2011 Supervisorial District Boundaries (Official)',\n",
    "                                    'Board Approved Statistical Areas',\\\n",
    "                                     'OWNER ID']\n",
    "        keyInspectFacility = [\"FACILITY ID\",'FACILITY NAME',\\\n",
    "                                   'FACILITY ADDRESS','FACILITY CITY',\\\n",
    "                                    'FACILITY ZIP',\n",
    "                                    'Location', 'Census Tracts 2010',\\\n",
    "                                    '2011 Supervisorial District Boundaries (Official)',\n",
    "                                    'Board Approved Statistical Areas',\\\n",
    "                                     'OWNER ID']\n",
    "    \n",
    "        inspectFacility = self.removeDup(dataInspections, keyInspectFacility)\n",
    "    \n",
    "        inspectFacility = inspectFacility.reindex(columns = keyFacility )\n",
    "    \n",
    "        #=== fill missing data with None, as the schema reqired\n",
    "        inspectFacility = inspectFacility.where(pd.notnull(inspectFacility), None)\n",
    "    \n",
    "        \n",
    "        self.sqlUploadPandas(self.dbEngine, inspectFacility, keyFacility)\n",
    "        self.sqlInsertTempTable(self.dbEngine,'facility', 'temp', \"FACILITY ID\")\n",
    "        \n",
    "        #==================== program element =========================\n",
    "        keyProgElem = [\"PROGRAM ELEMENT (PE)\",\\\n",
    "                   \"PE DESCRIPTION\",\\\n",
    "                   \"SEAT\"]\n",
    "        \n",
    "        #Program element is an special case where there are only 18 of PE and PE DESCRIPTION and seat\n",
    "        # are always the same.\n",
    "            \n",
    "        #dataProgElem = dataInspections[keyProgElem].drop_duplicates(subset=\"PROGRAM ELEMENT (PE)\")\n",
    "        dataProgElem = dataInspections.dropna()\n",
    "        \n",
    "        \n",
    "        self.sqlUploadPandas(self.dbEngine,  dataProgElem ,  keyProgElem )\n",
    "        self.sqlInsertTempTable(self.dbEngine,'program_elem', 'temp', \"PROGRAM ELEMENT (PE)\")\n",
    "       \n",
    "         #===================  Program ======================================== \n",
    "    \n",
    "        keyProgram = ['RECORD ID', ' PROGRAM NAME',\\\n",
    "                                     'PROGRAM ELEMENT (PE)',\"FACILITY ID\"]\n",
    "        keyInspectProgram  = ['RECORD ID',\\\n",
    "                                     'PROGRAM ELEMENT (PE)',\"FACILITY ID\"]\n",
    "    \n",
    "        inspectProgram = self.removeDup(dataInspections,keyInspectProgram )\n",
    "        \n",
    "        #=== fill missing data with None, as schema reqired\n",
    "        inspectProgram = inspectProgram.reindex(columns = keyProgram )\n",
    "        \n",
    "        inspectProgram  = inspectProgram.where(pd.notnull(inspectProgram), None)\n",
    "    \n",
    "        self.sqlUploadPandas(self.dbEngine, inspectProgram,  keyProgram )\n",
    "        self.sqlInsertTempTable(self.dbEngine,'program', 'temp', \"RECORD ID\")\n",
    "        \n",
    "         #==============    finally inspection ================================\n",
    "    \n",
    "        keyInspection = ['SERIAL NUMBER','ACTIVITY DATE', 'OWNER ID',\\\n",
    "                                       'FACILITY ID', 'RECORD ID','PROGRAM STATUS',\\\n",
    "                                       'SERVICE CODE', 'SCORE', 'GRADE',\\\n",
    "                                       'EMPLOYEE ID']\n",
    "    \n",
    "        dataInspect = self.removeDup(dataInspections, keyInspection)\n",
    "        \n",
    "        #convert the date to sql date formate\n",
    "        dataInspect['ACTIVITY DATE'] = pd.to_datetime(dataInspections['ACTIVITY DATE'],\\\n",
    "                                                      format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "        #cast the column to number and set null to None\n",
    "        dataInspect.loc[:,'SCORE'] = pd.to_numeric(dataInspect['SCORE'],\\\n",
    "                                                   errors='coerce')\n",
    "        \n",
    "        #change all nan value to something sql can understand\n",
    "        dataInspect = dataInspect.where(dataInspect.notnull(), None)\n",
    "        dataInspect =dataInspect.dropna()\n",
    "        \n",
    "        self.sqlUploadPandas(self.dbEngine, dataInspect,  keyInspection )\n",
    "        self.sqlInsertTempTable(self.dbEngine,\"inspections\", 'temp', \"RECORD ID\")\n",
    "        \n",
    "    \n",
    "        print (\"Inspections loaded in %.2f\" %(time.time()-start))\n",
    "           \n",
    "#============= End of Inspections =============================================================\n",
    "\n",
    "    #============ Start of violations ============================================\n",
    "    def uploadSqlViolations(self,dataViolations):\n",
    "        start = time.time()\n",
    "        \n",
    "        #connect to dp if there is no connection\n",
    "        if self.dbEngine ==None:\n",
    "            self.connect()\n",
    "        #==========================================================================\n",
    "        #violations.csv does not require spliting. But because it does not \n",
    "        #have unique id data base need to be plage of dupicate after update\n",
    "\n",
    "        dataViolations.drop_duplicates(inplace = True)\n",
    "\n",
    "\n",
    "        keyviolation = [\"SERIAL NUMBER\", \"VIOLATION  STATUS\",\\\n",
    "                         \"VIOLATION CODE\",\"VIOLATION DESCRIPTION\",\n",
    "                         \"POINTS\"]\n",
    "        #it can be directly upload to db\n",
    "        dataViolations.to_sql(name='violation',con=self.dbEngine, if_exists='append',\\\n",
    "                          index = False ,chunksize=50)\n",
    "        #clean up dupicated\n",
    "        mysql = \"\"\"CREATE TABLE copy_violation SELECT DISTINCT `SERIAL NUMBER`,\\\n",
    "                    `VIOLATION  STATUS`,`VIOLATION CODE`,\n",
    "                    `VIOLATION DESCRIPTION`, `POINTS`\n",
    "                    FROM violation\"\"\"\n",
    "        self.dbEngine.execute(mysql)\n",
    "\n",
    "        mysql = \"\"\"DROP TABLE violation;\"\"\"\n",
    "        self.dbEngine.execute(mysql)\n",
    "        mysql = \"ALTER TABLE copy_violation RENAME TO violation;\"\n",
    "        self.dbEngine.execute(mysql)\n",
    "\n",
    "        print (\"Violations loaded in %.2f\" %(time.time()-start))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing part of the program!!!!!!\n",
    "class YorkProcessing():\n",
    "    dB = None\n",
    "    def __init__(self, dbUsername, dbPassword, dbIp, dbName):\n",
    "        self.dB = YorkDb(dbUsername, dbPassword, dbIp, dbName)\n",
    "        \n",
    "        \n",
    "    #============= this do the reading of the files and clean them as they pass=============\n",
    "    #It will return data in pandas dataframe\n",
    "    def readCsvData(self,path, idSwidch = None, encode =\"utf-8-sig\" ):\n",
    "        #load and remove Byte Order Mark\n",
    "        with open(path, encoding=encode) as file:\n",
    "            rawData = file.readlines()\n",
    "        data = [] #list to store the data\n",
    "\n",
    "        #get header\n",
    "        title = (rawData[0].rstrip(\"\\n\").split(\",\"))\n",
    "\n",
    "        #change thet id if requested in preperation to Mongodb \n",
    "        if idSwidch != None:\n",
    "            for i, k in enumerate (title):\n",
    "                if idSwidch == k:\n",
    "                    title[i] = \"_id\"\n",
    "\n",
    "        # get the rest of the data line by line\n",
    "        for g, line in enumerate (rawData[1:-1]):\n",
    "            line = (line.rstrip(\"\\n\"))   # strip off the endline\n",
    "            #Pattern match to ignore , within doubele quote otherwise split comma \n",
    "            tempsplit=re.split(\",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\", line) \n",
    "            #Match the column to the data and put it into list of dictionary\n",
    "            templine = {i:tempsplit[k] for k,i in enumerate (title)}\n",
    "            data.append(templine)\n",
    "        #this part extract seat from \"PE DESCRIPTION\" and put it into an extra dictionary pair\n",
    "        for k,i in enumerate (data):\n",
    "            try:\n",
    "                #make sure PE exist\n",
    "                if \"PE DESCRIPTION\" in i:\n",
    "                    if \"(\" in i[\"PE DESCRIPTION\"] != None:\n",
    "                        #find the index between the ()\n",
    "                        braketPos = list(re.finditer(r'\\(.*\\)',i[\"PE DESCRIPTION\"], flags = re.IGNORECASE))[0].span()\n",
    "                        #this make new dictionary Seat\n",
    "                        #Removing the comma\n",
    "                        tempSeat = i[\"PE DESCRIPTION\"][braketPos[0]+1:braketPos[1]-1].replace(\",\",\"\")\n",
    "                        #correct seats\n",
    "                        \n",
    "                        #=============== correct the seats as we read data in ===========================================\n",
    "                        if \"sf\" not in tempSeat.lower():\n",
    "                            if float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])<31 :\n",
    "                                tempSeat = \"0-30\"\n",
    "                            elif float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])<61:\n",
    "                                tempSeat = \"31-60\"\n",
    "                            elif float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])<151:\n",
    "                                tempSeat = \"61-150\"\n",
    "                            elif float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])<1999:\n",
    "                                tempSeat = \"150 +\"\n",
    "                            elif float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])>1998:\n",
    "                                tempSeat = \"1-1,999 SF\"\n",
    "                            else:\n",
    "                                tempSeat = \"2,000+ SF\"\n",
    "                        else:\n",
    "                            if float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])<2000:\n",
    "                                tempSeat = \"1-1,999 SF\"\n",
    "                            if float(re.findall(r\"(\\d+)(?!.*\\d)\", tempSeat ) [0])>1999:\n",
    "                                tempSeat = \"2,000+ SF\"\n",
    "                        \n",
    "                        #write seat to dictionary ======================================================================    \n",
    "                        data[k].update({\"SEAT\":tempSeat})\n",
    "\n",
    "                        #Join the rest backup\n",
    "                        newPE = (i[\"PE DESCRIPTION\"][:braketPos[0]]+i[\"PE DESCRIPTION\"][braketPos[1]:]).replace(\"SEATS\",\"\")\n",
    "                        data[k].update({\"PE DESCRIPTION\":newPE})\n",
    "                    else:\n",
    "                        #If no () set seat to nan\n",
    "                        data[k].update({\"SEAT\":np.nan})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    #==========Read the first column and decide which data file it is\n",
    "    \n",
    "    def dataToDb(self,dataFrame):\n",
    "        try:\n",
    "            #Inventroy\n",
    "            if dataFrame.columns[0] == 'FACILITY ID':\n",
    "            \n",
    "                self.dB.uploadSqlInventroy(dataFrame)\n",
    "                print(\"inventroy\")\n",
    "            #Violation\n",
    "            elif dataFrame.columns[0] == 'SERIAL NUMBER':\n",
    "                self.dB.uploadSqlViolations(dataFrame)\n",
    "                print(\"violation\")\n",
    "            #Inspections\n",
    "            elif dataFrame.columns[0] == 'ACTIVITY DATE':\n",
    "                self.dB.uploadSqlInspections(dataFrame)\n",
    "                print(\"inspections\")\n",
    "            else:\n",
    "                print(\"Wrong file\")\n",
    "                return False\n",
    "        except():\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    #============== just getting a connection to our SQL server =================================  \n",
    "    def connectToDb(self):\n",
    "        return self.dB.connect()\n",
    "    def checkConnection(self):\n",
    "        if self.dB.dbEngine == None:\n",
    "            self.connectToDb()\n",
    "            \n",
    "    #ploting part of the processing\n",
    "    def statPlot(self, option):\n",
    "        #ploting option so far \"ZIP Code\", \"Seat Type\", violation\n",
    "        if option == \"Seat Type\":\n",
    "            try:\n",
    "                self.getSeatPlot()\n",
    "            except:\n",
    "                print (\"Seat plot issuse\")\n",
    "                return False\n",
    "        elif option ==\"Zip Code\":\n",
    "            try:\n",
    "                self.getZipPlot()\n",
    "            except:\n",
    "                print (\"Zip plot issuse\")\n",
    "                return False\n",
    "        elif option ==\"Violation Code\":\n",
    "            try:\n",
    "                self.vioPlot()\n",
    "            except:\n",
    "                print (\"vio plot issuse\")\n",
    "                return False\n",
    "        elif option ==\"Zip Correlation\":\n",
    "            try:\n",
    "                self.corrPlot()\n",
    "            except:\n",
    "                print (\"corr plot issuse\")\n",
    "                return False\n",
    "            \n",
    "            \n",
    "        return True\n",
    "            \n",
    "        \n",
    "    \n",
    "    #============plot the seat data==================================================\n",
    "    def getSeatPlot(self):\n",
    "        #ask the master mind for data aka our all controling sql server\n",
    "        sql =\"\"\"SELECT inspections.`SCORE`, program_elem.`SEAT`\n",
    "        ,Year(inspections.`ACTIVITY DATE`)\n",
    "        FROM inspections\\\n",
    "        LEFT JOIN program\\\n",
    "        ON inspections.`RECORD ID` = program.`RECORD ID`\\\n",
    "        LEFT JOIN program_elem\\\n",
    "        ON program.`PROGRAM ELEMENT (PE)` = program_elem.`PROGRAM ELEMENT (PE)`\n",
    "        WHERE inspections.`PROGRAM STATUS` = \"ACTIVE\";\"\"\"\n",
    "        try:\n",
    "            self.checkConnection()\n",
    "            k = self.dB.dbEngine.execute(sql)\n",
    "        except:\n",
    "            return False\n",
    "        myresult = k.fetchall()\n",
    "        \n",
    "        #put data into datframe\n",
    "        data = pd.DataFrame(myresult,columns= [\"SCORE\",\"SEAT\", \"Date\"])\n",
    "        \n",
    "        #goup up data and seat and get the stat\n",
    "        finalData = data.groupby([data.Date, 'SEAT'])['SCORE'].agg(['mean', lambda x:x.mode(), 'median'])\n",
    "        finalData = finalData.reset_index()\n",
    "        \n",
    "        #going to plot this in 4 graphs so spliting the year here\n",
    "        \n",
    "        numYear = finalData[\"Date\"].unique()\n",
    "        #setting up the graph\n",
    "        fig, ax = plt.subplots(len(numYear),1,figsize=(10,10))\n",
    "        for i,y in enumerate (numYear):\n",
    "            #get the data for each year\n",
    "            year= finalData[finalData[\"Date\"] == y]\n",
    "            \n",
    "            #set the x y label\n",
    "            labels = finalData[\"SEAT\"]\n",
    "            #generate the x steps\n",
    "            x = np.arange(len(year[\"SEAT\"]))\n",
    "            \n",
    "            # the width of the bars\n",
    "            width = 0.25 \n",
    "            \n",
    "            #plot the data\n",
    "            ax[i].barh(x - width, year[\"mean\"], width, label='Mean')\n",
    "            ax[i].barh(x , year[\"<lambda_0>\"], width, label='Mode')\n",
    "            ax[i].barh(x + width, year[\"median\"], width, label='Median')\n",
    "            \n",
    "            #set the x range\n",
    "            mmin = np.min(year.iloc[:,[2,3,4]].min())\n",
    "            mmax = np.max(year.iloc[:,[2,3,4]].max())\n",
    "            ax[i].set_xlim([mmin*0.98, mmax*1.02])\n",
    "            \n",
    "            # Add some text for labels, title and custom y-axis\n",
    "            ax[i].set_ylabel('SEAT')\n",
    "            ax[i].set_title('%s Score'%y)\n",
    "            ax[i].set_yticks(x)\n",
    "            ax[i].set_yticklabels(labels)\n",
    "            ax[i].legend()\n",
    "            fig.subplots_adjust(hspace=0.4)\n",
    "        plt.show(block = False)\n",
    "        return True\n",
    "    #============Plot zip data ==========================================================\n",
    "    def getZipPlot(self):\n",
    "        \n",
    "        #ask the goddness of sql to get use zip code score and date\n",
    "        sql =\"\"\"SELECT DATE_FORMAT(`ACTIVITY DATE`,'%Y') as \"Year\", `SCORE`,\n",
    "                LEFT(facility.`FACILITY ZIP`,5)\n",
    "                FROM inspections\\\n",
    "                LEFT JOIN facility\\\n",
    "                ON inspections.`FACILITY ID` = facility.`FACILITY ID`\n",
    "                WHERE inspections.`PROGRAM STATUS` = \"ACTIVE\";\"\"\"\n",
    "        try:\n",
    "            self.checkConnection()\n",
    "            k = self.dB.dbEngine.execute(sql)\n",
    "        except:\n",
    "            return False\n",
    "        #getting the data into dataframe and label the columns\n",
    "        myresult = k.fetchall()        \n",
    "        data = pd.DataFrame(myresult,columns= [\"Date\",\"SCORE\",\"FACILITY ZIP\"])\n",
    "        # do the magic here grouping data and zip and calculate the stat \n",
    "        finalData= data.groupby([data.Date, \"FACILITY ZIP\"])['SCORE'].agg(['mean', lambda x:x.mode()[0], 'median'])\n",
    "        #put things back in columns \n",
    "        finalData = finalData.reset_index()\n",
    "        \n",
    "        #going to plot this in 4 graphs so spliting the year here\n",
    "        numYear = finalData[\"Date\"].unique()\n",
    "        \n",
    "        #setting up the graph\n",
    "        fig, ax = plt.subplots(len(numYear),1,figsize=(10,10))\n",
    "        fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "        for i,y in enumerate (numYear):\n",
    "\n",
    "            year = finalData[finalData[\"Date\"] == y]\n",
    "            year = year.astype(float)\n",
    "            #Rebinning the data\n",
    "            bins = list(range(int(np.min(year[\"FACILITY ZIP\"])),\\\n",
    "                      int(np.max(year[\"FACILITY ZIP\"])),50))\n",
    "            groups = year.groupby(pd.cut(year[\"FACILITY ZIP\"], bins))\n",
    "\n",
    "            # Get the mean of b, binned by the values in a\n",
    "            finalMean = groups.agg([np.mean, np.std]) \n",
    "\n",
    "            #==============doing the ploting =============================================\n",
    "            ax[i].scatter(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"mean\"][\"mean\"],\\\n",
    "                          color=\"b\", marker = \"x\", label='Mean')\n",
    "            ax[i].errorbar(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"mean\"][\"mean\"],\\\n",
    "                          xerr=finalMean[\"FACILITY ZIP\"][\"std\"], yerr = finalMean[\"mean\"][\"std\"],\\\n",
    "                           fmt='',ls='none', color=\"b\")\n",
    "            ax[i].scatter(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"<lambda_0>\"][\"mean\"],\\\n",
    "                          color=\"r\", marker = \"4\", label='Mode')\n",
    "            ax[i].errorbar(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"<lambda_0>\"][\"mean\"],\\\n",
    "                          xerr=finalMean[\"FACILITY ZIP\"][\"std\"], yerr = finalMean[\"<lambda_0>\"][\"std\"],\\\n",
    "                           fmt='',ls='none',color=\"r\")\n",
    "            ax[i].scatter(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"median\"][\"mean\"],\\\n",
    "                          color=\"g\", marker = \"*\", label='Median')\n",
    "            ax[i].errorbar(finalMean[\"FACILITY ZIP\"][\"mean\"],finalMean[\"median\"][\"mean\"],\\\n",
    "                          xerr=finalMean[\"FACILITY ZIP\"][\"std\"], yerr = finalMean[\"median\"][\"std\"],\\\n",
    "                           fmt='',ls='none',color=\"g\")\n",
    "\n",
    "            # Add some text for labels, title and custom y-axis\n",
    "            ax[i].set_ylabel('SCORE')\n",
    "            ax[i].set_title('%s Zip Code'%y)\n",
    "            ax[i].legend(loc='lower left')\n",
    "            mmin = np.min(year.iloc[:,[2,3,4]].min())\n",
    "            mmax = np.max(year.iloc[:,[2,3,4]].max())\n",
    "            ax[i].set_ylim([mmin*0.98, mmax*1.02])\n",
    "\n",
    "\n",
    "        ax[len(numYear)-1].set_xlabel(\"Zip Code (Bin size 50)\")\n",
    "        plt.show(block = False)\n",
    "        return True\n",
    "    #====================Plot violation ========================================\n",
    "    #again ask for data\n",
    "    def vioPlot(self):\n",
    "        sql = \"\"\"SELECT violation.`VIOLATION CODE` AS code,count(`VIOLATION CODE`) \\\n",
    "              FROM violation\\\n",
    "              LEFT JOIN inspections\\\n",
    "              ON inspections.`SERIAL NUMBER` = violation.`SERIAL NUMBER`\\\n",
    "              WHERE inspections.`PROGRAM STATUS` = \"ACTIVE\"\\\n",
    "              GROUP BY `VIOLATION CODE`\"\"\"\n",
    "        try:\n",
    "            self.checkConnection()\n",
    "            k = self.dB.dbEngine.execute(sql)\n",
    "        except:\n",
    "            return False\n",
    "        myresult = k.fetchall()\n",
    "        #data into dataframe for processing\n",
    "        data = pd.DataFrame(myresult,columns= [\"V code\",\"Count\"])\n",
    "        #sort the data so it can be plot in in order\n",
    "        data.sort_values(\"Count\", inplace = True, ascending = False)\n",
    "        \n",
    "        #===== work out the step size for 6 graph \n",
    "        end = int(len(data[\"V code\"]))\n",
    "        ss = end/6\n",
    "        ss = int(ss)\n",
    "        print (ss)\n",
    "        start = 0\n",
    "        #===get ready to plot the data\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        fig.tight_layout(pad=1)\n",
    "        #hex coloring =======================================\n",
    "        colour = [\"6930c3\",\"5e60ce\",\"5390d9\",\"48bfe3\",\"64dfdf\",\"72efdd\",\"80ffdb\"]\n",
    "        colour = [\"#\" + c for c in colour]\n",
    "        #=========start the ploting\n",
    "        for j,i in enumerate (range(ss,end+1,ss)):\n",
    "        \n",
    "            plt.subplot(3,2,j+1)\n",
    "            plt.suptitle(\"Establishment Violations\")\n",
    "            plt.barh(data[\"V code\"][start:i], data[\"Count\"][start:i],color =colour[j])\n",
    "            #label y \n",
    "            start = start + ss\n",
    "            if j in [0,2,4]:\n",
    "                plt.ylabel(\"Violation Code\")\n",
    "            #only put xlabel at the bottom two plots\n",
    "            if j >3:\n",
    "                plt.xlabel(\"Number of active Establishment (Counts)\")\n",
    "        plt.show(block = False)\n",
    "        return True\n",
    "    #==================Plot correlation =============================\n",
    "    def corrPlot(self):\n",
    "        sql = \"\"\"SELECT LEFT(facility.`FACILITY ZIP`,5) AS code,\\\n",
    "              count(DISTINCT facility.`FACILITY ID`),\\\n",
    "              count(`VIOLATION CODE`),\\\n",
    "              count(`VIOLATION CODE`)/count(DISTINCT facility.`FACILITY ID`)      \n",
    "              FROM facility\\\n",
    "              RIGHT JOIN inspections\\\n",
    "                ON inspections.`FACILITY ID` = facility.`FACILITY ID`\n",
    "              RIGHT JOIN violation\\\n",
    "              ON inspections.`SERIAL NUMBER` = violation.`SERIAL NUMBER`\\\n",
    "              WHERE inspections.`PROGRAM STATUS` = \"ACTIVE\"\\\n",
    "              GROUP BY LEFT(facility.`FACILITY ZIP`,5)\"\"\"\n",
    "        try:\n",
    "            self.checkConnection()\n",
    "            k = self.dB.dbEngine.execute(sql)\n",
    "        except:\n",
    "            return False\n",
    "        myresult = k.fetchall()\n",
    "        #data into dataframe for processing\n",
    "        data =pd.DataFrame(myresult, columns= [\"ZIP\",\"No Fac\",\"No Vio\",\"v/F\"]).astype(float)\n",
    "        stippedData = data[data[\"No Fac\"]>7]\n",
    "        removedHigh = stippedData[stippedData[\"ZIP\"]<92000]\n",
    "        std = removedHigh[\"v/F\"].std()\n",
    "        mean = removedHigh[\"v/F\"].mean()\n",
    "        plt.figure()\n",
    "        plt.scatter(removedHigh[\"ZIP\"],removedHigh[\"v/F\"])\n",
    "        plt.errorbar(removedHigh[\"ZIP\"],removedHigh[\"v/F\"],yerr = std,ls = \"none\", fmt=\"\")\n",
    "        plt.fill_between(removedHigh[\"ZIP\"], (mean-std), (mean+std),alpha = 0.2, label = r'$\\sigma$')\n",
    "        plt.hlines(mean, 89900, 91900, color =\"r\", label = \"Mean\") \n",
    "        plt.ylabel(\"Violations per facility\")\n",
    "        plt.xlabel(\"Zip Code\") \n",
    "        plt.legend()\n",
    "        plt.show(block= False)\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventroy loaded in 8.28\n",
      "inventroy\n",
      "Inspections loaded in 47.81\n",
      "inspections\n"
     ]
    }
   ],
   "source": [
    "#get processing\n",
    "y = YorkProcessing(database_username, database_password, database_ip, database_name)\n",
    "#load data into memory and some small clean up              \n",
    "pathIns= \"DataSet1\\\\Inspections.csv\"\n",
    "dataInspections = y.readCsvData(pathIns)\n",
    "pathInv= \"DataSet1\\\\Inventroy.csv\"\n",
    "dataInventroy   = y.readCsvData(pathInv)\n",
    "pathVio = \"DataSet1\\\\violations.csv\"\n",
    "dataViolations  = y.readCsvData(pathVio)   \n",
    "y.dataToDb(dataInventroy)\n",
    "y.dataToDb(dataInspections)\n",
    "y.dataToDb(dataViolations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
